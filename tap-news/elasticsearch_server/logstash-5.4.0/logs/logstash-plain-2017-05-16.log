[2017-05-16T01:18:03,217][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-05-16T01:18:03,273][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-05-16T11:24:49,882][ERROR][logstash.agent           ] Cannot create pipeline {:reason=>"Expected one of #, in, not , ==, !=, <=, >=, <, >, =~, !~, and, or, xor, nand, { at line 10, column 12 (byte 181) after filter {\n  if[type] "}
[2017-05-16T11:25:35,622][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@localhost:9200/]}}
[2017-05-16T11:25:35,628][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://elastic:xxxxxx@localhost:9200/, :path=>"/"}
[2017-05-16T11:25:35,752][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=>#<URI::HTTP:0x3667c0d7 URL:http://elastic:xxxxxx@localhost:9200/>, :error_type=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=>"Elasticsearch Unreachable: [http://elastic:xxxxxx@localhost:9200/][Manticore::SocketException] Connection refused (Connection refused)"}
[2017-05-16T11:25:35,760][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2017-05-16T11:25:35,768][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://elastic:xxxxxx@localhost:9200/][Manticore::SocketException] Connection refused (Connection refused) {:url=>http://elastic:xxxxxx@localhost:9200/, :error_message=>"Elasticsearch Unreachable: [http://elastic:xxxxxx@localhost:9200/][Manticore::SocketException] Connection refused (Connection refused)", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2017-05-16T11:25:35,769][ERROR][logstash.outputs.elasticsearch] Failed to install template. {:message=>"Elasticsearch Unreachable: [http://elastic:xxxxxx@localhost:9200/][Manticore::SocketException] Connection refused (Connection refused)", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :backtrace=>["/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/vendor/bundle/jruby/1.9/gems/logstash-output-elasticsearch-6.3.0-java/lib/logstash/outputs/elasticsearch/http_client/pool.rb:287:in `perform_request_to_url'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/vendor/bundle/jruby/1.9/gems/logstash-output-elasticsearch-6.3.0-java/lib/logstash/outputs/elasticsearch/http_client/pool.rb:273:in `perform_request'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/vendor/bundle/jruby/1.9/gems/logstash-output-elasticsearch-6.3.0-java/lib/logstash/outputs/elasticsearch/http_client/pool.rb:363:in `with_connection'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/vendor/bundle/jruby/1.9/gems/logstash-output-elasticsearch-6.3.0-java/lib/logstash/outputs/elasticsearch/http_client/pool.rb:272:in `perform_request'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/vendor/bundle/jruby/1.9/gems/logstash-output-elasticsearch-6.3.0-java/lib/logstash/outputs/elasticsearch/http_client/pool.rb:280:in `get'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/vendor/bundle/jruby/1.9/gems/logstash-output-elasticsearch-6.3.0-java/lib/logstash/outputs/elasticsearch/http_client.rb:83:in `get_version'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/vendor/bundle/jruby/1.9/gems/logstash-output-elasticsearch-6.3.0-java/lib/logstash/outputs/elasticsearch/template_manager.rb:16:in `get_es_version'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/vendor/bundle/jruby/1.9/gems/logstash-output-elasticsearch-6.3.0-java/lib/logstash/outputs/elasticsearch/template_manager.rb:20:in `get_es_major_version'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/vendor/bundle/jruby/1.9/gems/logstash-output-elasticsearch-6.3.0-java/lib/logstash/outputs/elasticsearch/template_manager.rb:7:in `install_template'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/vendor/bundle/jruby/1.9/gems/logstash-output-elasticsearch-6.3.0-java/lib/logstash/outputs/elasticsearch/common.rb:54:in `install_template'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/vendor/bundle/jruby/1.9/gems/logstash-output-elasticsearch-6.3.0-java/lib/logstash/outputs/elasticsearch/common.rb:21:in `register'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/logstash-core/lib/logstash/output_delegator_strategies/shared.rb:9:in `register'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/logstash-core/lib/logstash/output_delegator.rb:41:in `register'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/logstash-core/lib/logstash/pipeline.rb:268:in `register_plugin'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/logstash-core/lib/logstash/pipeline.rb:279:in `register_plugins'", "org/jruby/RubyArray.java:1613:in `each'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/logstash-core/lib/logstash/pipeline.rb:279:in `register_plugins'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/logstash-core/lib/logstash/pipeline.rb:288:in `start_workers'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/logstash-core/lib/logstash/pipeline.rb:214:in `run'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/logstash-core/lib/logstash/agent.rb:398:in `start_pipeline'"]}
[2017-05-16T11:25:35,770][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>[#<URI::Generic:0x557ea1f8 URL://localhost:9200>]}
[2017-05-16T11:25:35,855][INFO ][logstash.filters.geoip   ] Using geoip database {:path=>"/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/vendor/bundle/jruby/1.9/gems/logstash-filter-geoip-4.0.4-java/vendor/GeoLite2-City.mmdb"}
[2017-05-16T11:25:35,884][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>6, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>750}
[2017-05-16T11:25:36,229][INFO ][logstash.pipeline        ] Pipeline main started
[2017-05-16T11:25:36,332][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-05-16T11:25:40,763][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://elastic:xxxxxx@localhost:9200/, :path=>"/"}
[2017-05-16T11:25:40,778][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=>#<URI::HTTP:0x35dd4188 URL:http://elastic:xxxxxx@localhost:9200/>, :error_type=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=>"Elasticsearch Unreachable: [http://elastic:xxxxxx@localhost:9200/][Manticore::SocketException] Connection refused (Connection refused)"}
[2017-05-16T11:25:45,781][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://elastic:xxxxxx@localhost:9200/, :path=>"/"}
[2017-05-16T11:25:45,786][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=>#<URI::HTTP:0x12d530d0 URL:http://elastic:xxxxxx@localhost:9200/>, :error_type=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=>"Elasticsearch Unreachable: [http://elastic:xxxxxx@localhost:9200/][Manticore::SocketException] Connection refused (Connection refused)"}
[2017-05-16T11:25:50,799][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://elastic:xxxxxx@localhost:9200/, :path=>"/"}
[2017-05-16T11:25:51,231][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>#<URI::HTTP:0x2f9243da URL:http://elastic:xxxxxx@localhost:9200/>}
[2017-05-16T11:50:13,150][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-05-16T11:50:13,164][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-05-16T11:50:26,238][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@localhost:9200/]}}
[2017-05-16T11:50:26,243][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://elastic:xxxxxx@localhost:9200/, :path=>"/"}
[2017-05-16T11:50:26,420][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>#<URI::HTTP:0xf195d6b URL:http://elastic:xxxxxx@localhost:9200/>}
[2017-05-16T11:50:26,422][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2017-05-16T11:50:26,485][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>50001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"_all"=>{"enabled"=>true, "norms"=>false}, "dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword"}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date", "include_in_all"=>false}, "@version"=>{"type"=>"keyword", "include_in_all"=>false}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2017-05-16T11:50:26,495][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>[#<URI::Generic:0x4a5d6256 URL://localhost:9200>]}
[2017-05-16T11:50:26,578][INFO ][logstash.filters.geoip   ] Using geoip database {:path=>"/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/vendor/bundle/jruby/1.9/gems/logstash-filter-geoip-4.0.4-java/vendor/GeoLite2-City.mmdb"}
[2017-05-16T11:50:26,598][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>6, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>750}
[2017-05-16T11:50:26,767][INFO ][logstash.pipeline        ] Pipeline main started
[2017-05-16T11:50:26,836][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-05-16T12:18:48,666][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-05-16T12:18:48,724][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-05-16T15:48:06,630][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>6, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>750}
[2017-05-16T15:48:06,957][INFO ][logstash.pipeline        ] Pipeline main started
[2017-05-16T15:48:07,064][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-05-16T15:48:22,527][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-05-16T15:48:22,556][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-05-16T15:53:33,891][ERROR][logstash.pipeline        ] Error registering plugin {:plugin=>"#<LogStash::FilterDelegator:0x3407faf7 @id=\"0c2942a26f2d971eb359b251ce40902b0b907977-2\", @klass=LogStash::Filters::Grok, @metric_events=#<LogStash::Instrument::NamespacedMetric:0x2fe9bca6 @metric=#<LogStash::Instrument::Metric:0x1eb7e9c1 @collector=#<LogStash::Instrument::Collector:0x4c47ea43 @agent=nil, @metric_store=#<LogStash::Instrument::MetricStore:0x479c717e @store=#<Concurrent::Map:0x25f2f9a7 @default_proc=nil>, @structured_lookup_mutex=#<Mutex:0x42ae539>, @fast_lookup=#<Concurrent::Map:0x774c020d @default_proc=nil>>>>, @namespace_name=[:stats, :pipelines, :main, :plugins, :filters, :\"0c2942a26f2d971eb359b251ce40902b0b907977-2\", :events]>, @logger=#<LogStash::Logging::Logger:0x61727e02 @logger=#<Java::OrgApacheLoggingLog4jCore::Logger:0x53570ad>>, @filter=<LogStash::Filters::Grok match=>{\"message\"=>\"[%{TIMESTAMP_ISO8601:timestamp} - %{DATA:file}:%{DATA:line} - %{LOGLEVEL:log-level} - %{DATA:method} ]: %{GREEDYDATA:message}\"}, remove_field=>[\"message\"], id=>\"0c2942a26f2d971eb359b251ce40902b0b907977-2\", enable_metric=>true, periodic_flush=>false, patterns_files_glob=>\"*\", break_on_match=>true, named_captures_only=>true, keep_empty_captures=>false, tag_on_failure=>[\"_grokparsefailure\"], timeout_millis=>30000, tag_on_timeout=>\"_groktimeout\">>", :error=>"empty range in char class: /[(?<TIMESTAMP_ISO8601:timestamp>(?:(?>\\d\\d){1,2})-(?:(?:0?[1-9]|1[0-2]))-(?:(?:(?:0[1-9])|(?:[12][0-9])|(?:3[01])|[1-9]))[T ](?:(?:2[0123]|[01]?[0-9])):?(?:(?:[0-5][0-9]))(?::?(?:(?:(?:[0-5]?[0-9]|60)(?:[:.,][0-9]+)?)))?(?:(?:Z|[+-](?:(?:2[0123]|[01]?[0-9]))(?::?(?:(?:[0-5][0-9])))))?) - (?<DATA:file>.*?):(?<DATA:line>.*?) - (?<LOGLEVEL:log-level>([Aa]lert|ALERT|[Tt]race|TRACE|[Dd]ebug|DEBUG|[Nn]otice|NOTICE|[Ii]nfo|INFO|[Ww]arn?(?:ing)?|WARN?(?:ING)?|[Ee]rr?(?:or)?|ERR?(?:OR)?|[Cc]rit?(?:ical)?|CRIT?(?:ICAL)?|[Ff]atal|FATAL|[Ss]evere|SEVERE|EMERG(?:ENCY)?|[Ee]merg(?:ency)?)) - (?<DATA:method>.*?) ]: (?<GREEDYDATA:message>.*)/m"}
[2017-05-16T15:53:33,900][ERROR][logstash.agent           ] Pipeline aborted due to error {:exception=>#<RegexpError: empty range in char class: /[(?<TIMESTAMP_ISO8601:timestamp>(?:(?>\d\d){1,2})-(?:(?:0?[1-9]|1[0-2]))-(?:(?:(?:0[1-9])|(?:[12][0-9])|(?:3[01])|[1-9]))[T ](?:(?:2[0123]|[01]?[0-9])):?(?:(?:[0-5][0-9]))(?::?(?:(?:(?:[0-5]?[0-9]|60)(?:[:.,][0-9]+)?)))?(?:(?:Z|[+-](?:(?:2[0123]|[01]?[0-9]))(?::?(?:(?:[0-5][0-9])))))?) - (?<DATA:file>.*?):(?<DATA:line>.*?) - (?<LOGLEVEL:log-level>([Aa]lert|ALERT|[Tt]race|TRACE|[Dd]ebug|DEBUG|[Nn]otice|NOTICE|[Ii]nfo|INFO|[Ww]arn?(?:ing)?|WARN?(?:ING)?|[Ee]rr?(?:or)?|ERR?(?:OR)?|[Cc]rit?(?:ical)?|CRIT?(?:ICAL)?|[Ff]atal|FATAL|[Ss]evere|SEVERE|EMERG(?:ENCY)?|[Ee]merg(?:ency)?)) - (?<DATA:method>.*?) ]: (?<GREEDYDATA:message>.*)/m>, :backtrace=>["org/jruby/RubyRegexp.java:1434:in `initialize'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/vendor/bundle/jruby/1.9/gems/jls-grok-0.11.4/lib/grok-pure.rb:127:in `compile'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/vendor/bundle/jruby/1.9/gems/logstash-filter-grok-3.3.1/lib/logstash/filters/grok.rb:274:in `register'", "org/jruby/RubyArray.java:1613:in `each'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/vendor/bundle/jruby/1.9/gems/logstash-filter-grok-3.3.1/lib/logstash/filters/grok.rb:269:in `register'", "org/jruby/RubyHash.java:1342:in `each'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/vendor/bundle/jruby/1.9/gems/logstash-filter-grok-3.3.1/lib/logstash/filters/grok.rb:264:in `register'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/logstash-core/lib/logstash/pipeline.rb:268:in `register_plugin'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/logstash-core/lib/logstash/pipeline.rb:279:in `register_plugins'", "org/jruby/RubyArray.java:1613:in `each'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/logstash-core/lib/logstash/pipeline.rb:279:in `register_plugins'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/logstash-core/lib/logstash/pipeline.rb:289:in `start_workers'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/logstash-core/lib/logstash/pipeline.rb:214:in `run'", "/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/logstash-core/lib/logstash/agent.rb:398:in `start_pipeline'"]}
[2017-05-16T15:53:33,939][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-05-16T15:53:36,917][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-05-16T15:55:03,212][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>6, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>750}
[2017-05-16T15:55:03,413][INFO ][logstash.pipeline        ] Pipeline main started
[2017-05-16T15:55:03,482][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-05-16T15:55:05,186][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-05-16T15:55:05,199][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-05-16T15:55:08,749][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-05-16T15:58:20,472][ERROR][logstash.agent           ] Cannot create pipeline {:reason=>"Expected one of #, \", ', } at line 12, column 5 (byte 257) after filter {\n  if[type] == \"system_log\"{\n\t  grok {\n\t  \t"}
[2017-05-16T15:59:00,170][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>6, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>750}
[2017-05-16T15:59:00,521][INFO ][logstash.pipeline        ] Pipeline main started
[2017-05-16T15:59:00,798][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-05-16T15:59:02,803][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-05-16T15:59:02,823][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-05-16T15:59:06,002][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-05-16T16:00:24,364][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>6, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>750}
[2017-05-16T16:00:24,494][INFO ][logstash.pipeline        ] Pipeline main started
[2017-05-16T16:00:24,558][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-05-16T16:00:26,139][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-05-16T16:00:26,172][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-05-16T16:00:28,520][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-05-16T16:01:03,349][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>6, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>750}
[2017-05-16T16:01:03,482][INFO ][logstash.pipeline        ] Pipeline main started
[2017-05-16T16:01:03,546][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-05-16T16:01:04,719][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-05-16T16:01:04,769][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-05-16T16:01:05,934][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2017-05-16T16:06:18,770][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@localhost:9200/]}}
[2017-05-16T16:06:18,774][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://elastic:xxxxxx@localhost:9200/, :path=>"/"}
[2017-05-16T16:06:19,495][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>#<URI::HTTP:0x719df384 URL:http://elastic:xxxxxx@localhost:9200/>}
[2017-05-16T16:06:19,497][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2017-05-16T16:06:19,584][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>50001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"_all"=>{"enabled"=>true, "norms"=>false}, "dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword"}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date", "include_in_all"=>false}, "@version"=>{"type"=>"keyword", "include_in_all"=>false}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2017-05-16T16:06:19,592][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>[#<URI::Generic:0x24325df6 URL://localhost:9200>]}
[2017-05-16T16:06:19,655][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>6, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>750}
[2017-05-16T16:06:20,527][INFO ][logstash.pipeline        ] Pipeline main started
[2017-05-16T16:06:20,834][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-05-16T17:20:47,167][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-05-16T17:20:47,877][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-05-16T17:22:09,425][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@localhost:9200/]}}
[2017-05-16T17:22:09,433][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://elastic:xxxxxx@localhost:9200/, :path=>"/"}
[2017-05-16T17:22:09,582][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>#<URI::HTTP:0x3a5321 URL:http://elastic:xxxxxx@localhost:9200/>}
[2017-05-16T17:22:09,583][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2017-05-16T17:22:09,641][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>50001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"_all"=>{"enabled"=>true, "norms"=>false}, "dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword"}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date", "include_in_all"=>false}, "@version"=>{"type"=>"keyword", "include_in_all"=>false}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2017-05-16T17:22:09,647][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>[#<URI::Generic:0x1f81b1cc URL://localhost:9200>]}
[2017-05-16T17:22:09,708][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>6, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>750}
[2017-05-16T17:22:10,017][INFO ][logstash.pipeline        ] Pipeline main started
[2017-05-16T17:22:10,080][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-05-16T17:22:54,416][FATAL][logstash.runner          ] Logstash could not be started because there is already another instance using the configured data directory.  If you wish to run multiple instances, you must change the "path.data" setting.
[2017-05-16T17:24:23,004][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-05-16T17:24:23,012][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-05-16T17:24:45,811][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@localhost:9200/]}}
[2017-05-16T17:24:45,817][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://elastic:xxxxxx@localhost:9200/, :path=>"/"}
[2017-05-16T17:24:45,943][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>#<URI::HTTP:0x7001ed62 URL:http://elastic:xxxxxx@localhost:9200/>}
[2017-05-16T17:24:45,945][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2017-05-16T17:24:45,994][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>50001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"_all"=>{"enabled"=>true, "norms"=>false}, "dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword"}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date", "include_in_all"=>false}, "@version"=>{"type"=>"keyword", "include_in_all"=>false}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2017-05-16T17:24:45,999][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>[#<URI::Generic:0x5887200d URL://localhost:9200>]}
[2017-05-16T17:24:46,050][INFO ][logstash.filters.geoip   ] Using geoip database {:path=>"/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/vendor/bundle/jruby/1.9/gems/logstash-filter-geoip-4.0.4-java/vendor/GeoLite2-City.mmdb"}
[2017-05-16T17:24:46,088][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>6, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>750}
[2017-05-16T17:24:46,226][INFO ][logstash.pipeline        ] Pipeline main started
[2017-05-16T17:24:46,273][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-05-16T17:24:59,881][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-05-16T17:24:59,890][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-05-16T20:28:15,098][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@localhost:9200/]}}
[2017-05-16T20:28:15,108][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://elastic:xxxxxx@localhost:9200/, :path=>"/"}
[2017-05-16T20:28:15,411][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>#<URI::HTTP:0x37714be URL:http://elastic:xxxxxx@localhost:9200/>}
[2017-05-16T20:28:15,412][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2017-05-16T20:28:15,485][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>50001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"_all"=>{"enabled"=>true, "norms"=>false}, "dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword"}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date", "include_in_all"=>false}, "@version"=>{"type"=>"keyword", "include_in_all"=>false}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2017-05-16T20:28:15,497][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>[#<URI::Generic:0x473455af URL://localhost:9200>]}
[2017-05-16T20:28:15,557][INFO ][logstash.filters.geoip   ] Using geoip database {:path=>"/home/tony/Desktop/tap-news/tap-news/elasticsearch_server/logstash-5.4.0/vendor/bundle/jruby/1.9/gems/logstash-filter-geoip-4.0.4-java/vendor/GeoLite2-City.mmdb"}
[2017-05-16T20:28:15,586][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>6, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>750}
[2017-05-16T20:28:15,782][INFO ][logstash.pipeline        ] Pipeline main started
[2017-05-16T20:28:15,841][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
